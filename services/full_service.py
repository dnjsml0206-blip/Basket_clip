# services/full_service.py
import os
import uuid
import subprocess
import wave
import contextlib
from typing import List, Dict, Optional

import numpy as np
import cv2

from services.store_service import load_store
# ë§¨ ìœ„ import ë¶€ë¶„ ì–´ë”˜ê°€ì— ì¶”ê°€
from services.full_sync_store import get_sync


TMP_DIR = os.path.join("results", "tmp_cross_edit")


# -------------------------------------------------------------
# TMP í´ë”ìƒì„±
# -------------------------------------------------------------
def _ensure_tmp():
    os.makedirs(TMP_DIR, exist_ok=True)


# -------------------------------------------------------------
# duration ê³„ì‚°
# -------------------------------------------------------------
def _get_duration(video_path: str) -> float:
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return 0.0
    fps = cap.get(cv2.CAP_PROP_FPS)
    total = cap.get(cv2.CAP_PROP_FRAME_COUNT)
    cap.release()
    if not fps or fps <= 0:
        return 0.0
    return float(total) / float(fps)


# =================================================================
# ğŸ”¥ ì˜¤ë””ì˜¤ ê¸°ë°˜ ì‹±í¬ (ìµœëŒ€ 30ì´ˆ)
# =================================================================

def _extract_wav_30s(input_video: str, output_wav: str, sample_rate: int = 16000):
    """ì•ìª½ ìµœëŒ€ 30ì´ˆ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
    _ensure_tmp()
    cmd = [
        "ffmpeg", "-y",
        "-i", input_video,
        "-vn",
        "-ac", "1",
        "-ar", str(sample_rate),
        "-t", "30",           # ğŸ”¥ 30ì´ˆê¹Œì§€ ì‚¬ìš©
        output_wav
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)


def _load_wav_numpy(path: str):
    with contextlib.closing(wave.open(path, "rb")) as w:
        frames = w.readframes(w.getnframes())
        sr = w.getframerate()
    data = np.frombuffer(frames, dtype=np.int16).astype(np.float32)
    return data, sr


def _compute_audio_offset_seconds_30s(video_a: str, video_b: str) -> float:
    """
    ë‘ ì˜ìƒì˜ ì• 30ì´ˆ ì˜¤ë””ì˜¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ offset ê³„ì‚°
    (ì–‘ìˆ˜ = B ì˜ìƒì´ ëŠ¦ê²Œ ì‹œì‘)
    """

    wav_a = os.path.join(TMP_DIR, f"{uuid.uuid4()}_a.wav")
    wav_b = os.path.join(TMP_DIR, f"{uuid.uuid4()}_b.wav")

    _extract_wav_30s(video_a, wav_a)
    _extract_wav_30s(video_b, wav_b)

    sig_a, sr = _load_wav_numpy(wav_a)
    sig_b, _ = _load_wav_numpy(wav_b)

    n = min(len(sig_a), len(sig_b))
    sig_a = sig_a[:n]
    sig_b = sig_b[:n]

    # ìµœëŒ€ Â±30ì´ˆ
    max_shift = sr * 30

    corr = np.correlate(sig_a, sig_b, mode="full")
    mid = len(corr) // 2
    limited_corr = corr[mid - max_shift : mid + max_shift + 1]

    best_index = np.argmax(limited_corr)
    lag = best_index - max_shift
    offset_seconds = lag / float(sr)

    print(f"ğŸµ Audio Sync Offset (Â±30s): {offset_seconds:.3f}s")

    # ì •ë¦¬
    try:
        os.remove(wav_a)
        os.remove(wav_b)
    except:
        pass

    return offset_seconds


def _sync_videos_audio30s(left_video: str, right_video: str):
    """
    ì˜¤ë””ì˜¤ ê¸°ë°˜ ì‹±í¬:
    offset > 0  â†’ right ëŠ¦ê²Œ ì‹œì‘ â†’ right ì•ë¶€ë¶„ offset ì»·
    offset < 0  â†’ left ëŠ¦ê²Œ ì‹œì‘  â†’ left ì•ë¶€ë¶„ |offset| ì»·
    """

    offset = _compute_audio_offset_seconds_30s(left_video, right_video)
    _ensure_tmp()

    out_left  = os.path.join(TMP_DIR, f"{uuid.uuid4()}_left.mp4")
    out_right = os.path.join(TMP_DIR, f"{uuid.uuid4()}_right.mp4")

    if offset > 0:
        # right ì˜ìƒì´ ëŠ¦ê²Œ ì‹œì‘ â†’ rightì—ì„œ offset ì˜ë¼ëƒ„
        subprocess.run([
            "ffmpeg", "-y",
            "-i", left_video,
            "-c", "copy", out_left
        ])
        subprocess.run([
            "ffmpeg", "-y",
            "-ss", str(offset), "-i", right_video,
            "-c", "copy", out_right
        ])
    else:
        # left ì˜ìƒì´ ëŠ¦ê²Œ ì‹œì‘
        off = abs(offset)
        subprocess.run([
            "ffmpeg", "-y",
            "-ss", str(off), "-i", left_video,
            "-c", "copy", out_left
        ])
        subprocess.run([
            "ffmpeg", "-y",
            "-i", right_video,
            "-c", "copy", out_right
        ])

    print("ğŸ¬ Audio sync complete.")
    return out_left, out_right


# =================================================================
# ğŸ”¥ ë³€í™”ëŸ‰ ê¸°ë°˜ ì¹´ë©”ë¼ ì„ íƒ (ë¹ˆ ì‹œê°„ ì—†ì´ ì „ì²´ ì»¤ë²„)
# =================================================================

def generate_full_coverage_segments(
    video_left: str,
    video_right: str,
    offset: float = 0.0,   # ğŸŸ© ì¶”ê°€
    duration_hint: Optional[float] = None,
    sustain_sec: float = 2.0,
    fps_fallback: float = 30.0,
) -> List[Dict]:

    store = load_store()
    left_data = next((d for d in store if d.get("video") == video_left), None)
    right_data = next((d for d in store if d.get("video") == video_right), None)

    if not left_data or not right_data:
        dur = duration_hint or 0
        return [{"start": 0, "end": dur, "target": "left"}]

    left_frames = left_data["frames"]
    right_frames = right_data["frames"]

    fps = min(left_data.get("fps", fps_fallback), right_data.get("fps", fps_fallback))

    n = min(len(left_frames), len(right_frames))
    if n == 0:
        dur = duration_hint or 0
        return [{"start": 0, "end": dur, "target": "left"}]

    step = int(round(fps))
    if step <= 0:
        step = 30

    samples = []
    for i in range(step, n, step):
        lf, rf = left_frames[i], right_frames[i]
        lf_prev, rf_prev = left_frames[i-step], right_frames[i-step]

        # ğŸŸ© ì‹±í¬ ì ìš©ëœ ì‹œê°„ ë°˜ì˜
        t_left  = lf["t"]
        t_right = rf["t"] + offset    # offsets ì ìš©!

        t = min(t_left, t_right)      # ë‘ ì˜ìƒ ì¤‘ ë™ì¼ ìˆœê°„ì„ ëŒ€í‘œí•˜ëŠ” ì‹œê°„

        pl, pr = lf["persons"], rf["persons"]
        pl_prev, pr_prev = lf_prev["persons"], rf_prev["persons"]

        pl_diff = pl - pl_prev
        pr_diff = pr - pr_prev
        samples.append((t, pl_diff, pr_diff))

    if not samples:
        dur = duration_hint or 0
        return [{"start": 0, "end": dur, "target": "left"}]

    if duration_hint:
        duration = duration_hint
    else:
        duration = samples[-1][0]

    cur_side = "left"
    seg_start = 0.0

    pending_side = None
    pending_start = None
    pending_threshold = None

    def compute_threshold(abs_cv):
        if abs_cv >= 8:
            return 0
        if abs_cv <= 2:
            return sustain_sec
        return sustain_sec * (1 - ((abs_cv - 2) / 6))

    prev_abs_cv = 0
    segments = []

    for t, pl_diff, pr_diff in samples:
        change = pr_diff - pl_diff
        abs_cv = abs(change)
        desired = "right" if change > 0 else "left"

        # ë°˜ëŒ€ë°©í–¥ ê°•í•œ ë³€í™” â†’ í›„ë³´ ì·¨ì†Œ
        if pending_side and desired != pending_side:
            if abs_cv >= 2:
                pending_side = None
                pending_start = None
                pending_threshold = None

        # ì¦‰ì‹œ ì „í™˜
        if abs_cv >= 8 and desired != cur_side:
            segments.append({"start": seg_start, "end": t, "target": cur_side})
            cur_side = desired
            seg_start = t
            pending_side = None
            pending_start = None
            pending_threshold = None
            prev_abs_cv = abs_cv
            continue

        # í›„ë³´ ì§„í–‰ ì¤‘ threshold ê°ì†Œ
        if pending_side and desired == pending_side:
            if abs_cv > prev_abs_cv:
                new_th = compute_threshold(abs_cv)
                if pending_threshold is None or new_th < pending_threshold:
                    pending_threshold = new_th

        # í›„ë³´ ì‹œì‘
        if desired != cur_side:
            if pending_side is None:
                pending_side = desired
                pending_start = t
                pending_threshold = compute_threshold(abs_cv)

        # í›„ë³´ í™•ì •
        if pending_side:
            if (t - pending_start) >= pending_threshold:
                segments.append({"start": seg_start, "end": pending_start, "target": cur_side})
                cur_side = pending_side
                seg_start = pending_start

                pending_side = None
                pending_start = None
                pending_threshold = None

        prev_abs_cv = abs_cv

    segments.append({"start": seg_start, "end": duration, "target": cur_side})
    return segments


# =================================================================
# FFmpeg concat
# =================================================================

def _build_ffmpeg_cross_edit(left_synced, right_synced, segments, output_path):
    _ensure_tmp()
    concat_list = os.path.join(TMP_DIR, f"{uuid.uuid4()}_concat.txt")
    temp_list = []

    for i, seg in enumerate(segments):
        start = seg["start"]
        end = seg["end"]
        if end <= start:
            continue

        dur = end - start
        src = left_synced if seg["target"] == "left" else right_synced
        out = os.path.join(TMP_DIR, f"{uuid.uuid4()}_p{i}.mp4")
        temp_list.append(out)

        subprocess.run([
            "ffmpeg", "-y",
            "-ss", str(start),
            "-i", src,
            "-t", str(dur),
            "-c", "copy",
            out
        ])

    with open(concat_list, "w") as f:
        for p in temp_list:
            f.write(f"file '{os.path.abspath(p)}'\n")

    subprocess.run([
        "ffmpeg", "-y",
        "-f", "concat", "-safe", "0",
        "-i", concat_list,
        "-c", "copy",
        output_path
    ])

    return output_path


# =================================================================
# FULL Export (í¸ì§‘ ê²°ê³¼ ì „ë‹¬)
# =================================================================

def export_full_from_segments(left_synced_path, right_synced_path, output_path, segments):
    norm = []
    for seg in segments:
        start = seg["start"]
        end = seg["end"]
        if end <= start:
            continue
        side = seg.get("side") or seg.get("target") or "left"
        target = "right" if side == "right" else "left"
        norm.append({"start": start, "end": end, "target": target})

    return _build_ffmpeg_cross_edit(left_synced_path, right_synced_path, norm, output_path)


# =================================================================
# ìë™ êµì°¨ í¸ì§‘
# =================================================================

def create_full_highlight(left_video_path, right_video_path, output_path, session_id):
    left_synced, right_synced = _sync_videos_audio30s(left_video_path, right_video_path)
    duration = min(_get_duration(left_synced), _get_duration(right_synced))

    segs = generate_full_coverage_segments(
        video_left=os.path.basename(left_video_path),
        video_right=os.path.basename(right_video_path),
        offset=offset,                 # ğŸŸ© ì¶”ê°€
        duration_hint=duration,
        sustain_sec=2.0,
    )

    return _build_ffmpeg_cross_edit(left_synced, right_synced, segs, output_path)


# =================================================================
# í¸ì§‘ í˜ì´ì§€ ì´ˆê¸° ì„¸ì…˜ ì¤€ë¹„
# =================================================================

def prepare_full_session(
    left_video_path: str,
    right_video_path: str,
    left_video_name: str,
    right_video_name: str,
    session_id: str,
    user_synced_left: Optional[str] = None,
    user_synced_right: Optional[str] = None,
) -> dict:
    """
    - user_synced_left/right ê°€ ë„˜ì–´ì˜¤ë©´: ê·¸ ê²½ë¡œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìœ ì €ê°€ ì‹±í¬ ì¡°ì • í›„ ìë¥¸ ì˜ìƒ)
    - ì•„ë‹ˆë©´: ê¸°ì¡´ì²˜ëŸ¼ ì˜¤ë””ì˜¤ 30ì´ˆ ê¸°ì¤€ ìë™ ì‹±í¬
    """
    # ğŸ”µ 1) ì‹±í¬ëœ ì˜ìƒ ê²½ë¡œ ê²°ì •
    if user_synced_left and user_synced_right:
        # full_sync_confirm â†’ apply_sync_cut ì—ì„œ ë§Œë“  'ì˜ë¦°' ì‹±í¬ ì˜ìƒ
        left_synced = user_synced_left
        right_synced = user_synced_right
    else:
        # ì˜ˆì „ ë°©ì‹: ì˜¤ë””ì˜¤ 30ì´ˆ ìë™ ì‹±í¬ (ë°±ì—… í”Œë¡œìš°)
        left_synced, right_synced = _sync_videos_audio30s(left_video_path, right_video_path)

    # ğŸ”µ 1-1) ì‹±í¬ offset ì¡°íšŒ (full_sync_store ì— ì €ì¥ëœ ê°’, float)
    sync_info = get_sync(left_video_name, right_video_name)
    # get_sync ê°€ float (ë˜ëŠ” None) ì„ ë°˜í™˜í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìºìŠ¤íŒ…
    offset = float(sync_info) if sync_info is not None else 0.0

    # ğŸ”µ 2) duration ê³„ì‚°
    duration = min(_get_duration(left_synced), _get_duration(right_synced))

    # ğŸ”µ 3) ì‚¬ëŒ ìˆ˜ ë³€í™”ëŸ‰ ê¸°ë°˜ full coverage ì„¸ê·¸ë¨¼íŠ¸
    segs = generate_full_coverage_segments(
        video_left=left_video_name,
        video_right=right_video_name,
        duration_hint=duration,
        sustain_sec=2.0
    )

    left_clips: List[Dict] = []
    right_clips: List[Dict] = []
    for s in segs:
        item = {"start": s["start"], "end": s["end"]}
        if s["target"] == "left":
            left_clips.append(item)
        else:
            right_clips.append(item)

    return {
        "session_id": session_id,
        "left_src": os.path.relpath(left_synced).replace("\\", "/"),
        "right_src": os.path.relpath(right_synced).replace("\\", "/"),
        "left_video": left_video_name,
        "right_video": right_video_name,
        "duration": float(duration),
        "left_clips": left_clips,
        "right_clips": right_clips,
        "offset": offset,   # â˜… ì—¬ê¸°ì„œ í…œí”Œë¦¿ìœ¼ë¡œ ë„˜ê²¨ì¤Œ
    }




def compute_auto_sync_offset(left_video, right_video):
    """ìœ ì €ì—ê²Œ ì¶”ì²œí•  ì˜¤ë””ì˜¤ ê¸°ë°˜ ì‹±í¬ê°’ ê³„ì‚° (Â±30s)"""
    return _compute_audio_offset_seconds_30s(left_video, right_video)

def apply_sync_cut(left_video, right_video, offset):
    """ì‚¬ìš©ìê°€ ì„ íƒí•œ offset(ì´ˆ)ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹¤ì œ ì‹±í¬ ì˜ìƒ ìƒì„±"""

    _ensure_tmp()

    left_out  = os.path.join(TMP_DIR, f"{uuid.uuid4()}_user_left.mp4")
    right_out = os.path.join(TMP_DIR, f"{uuid.uuid4()}_user_right.mp4")

    if offset > 0:
        # right ëŠ¦ìŒ â†’ right ì»·
        subprocess.run([
            "ffmpeg", "-y",
            "-i", left_video,
            "-c", "copy", left_out
        ])
        subprocess.run([
            "ffmpeg", "-y",
            "-ss", str(offset),
            "-i", right_video,
            "-c", "copy", right_out
        ])
    else:
        # left ëŠ¦ìŒ â†’ left ì»·
        off = abs(offset)
        subprocess.run([
            "ffmpeg", "-y",
            "-ss", str(off),
            "-i", left_video,
            "-c", "copy", left_out
        ])
        subprocess.run([
            "ffmpeg", "-y",
            "-i", right_video,
            "-c", "copy", right_out
        ])

    return left_out, right_out



import base64
import tempfile

def extract_wav_30s_base64(video_path: str) -> str:
    """ì• 30ì´ˆ wav ìƒì„±í•˜ê³  base64 ë¡œ ë°˜í™˜"""
    _ensure_tmp()

    temp_wav = os.path.join(TMP_DIR, f"{uuid.uuid4()}_preview.wav")

    subprocess.run([
        "ffmpeg", "-y",
        "-i", video_path,
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-t", "30",
        temp_wav
    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    with open(temp_wav, "rb") as f:
        encoded = base64.b64encode(f.read()).decode("utf-8")

    return "data:audio/wav;base64," + encoded


# =================================================================
# ì‚¬ìš©ì ì‹±í¬ í˜ì´ì§€ì—ì„œ ì‚¬ìš©í•˜ëŠ” "ìë™ ì¶”ì²œ sync offset"
# =================================================================

def compute_auto_sync_offset(left_video: str, right_video: str) -> float:
    """
    full_sync_adjust.html ì— í‘œì‹œí•  ìë™ ì˜¤ë””ì˜¤ ì‹±í¬ ì¶”ì²œê°’.
    ì˜¤ë””ì˜¤ 30ì´ˆ ê¸°ì¤€ ìë™ ì‹±í¬ offset ê³„ì‚°.
    """
    return _compute_audio_offset_seconds_30s(left_video, right_video)

def extract_waveform_png(video_path: str, width=900, height=80) -> str:
    """
    ì• 30ì´ˆ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œ í›„ íŒŒí˜• PNG Base64ë¡œ ë°˜í™˜
    """
    _ensure_tmp()

    wav = os.path.join(TMP_DIR, f"{uuid.uuid4()}_wave.wav")
    png = os.path.join(TMP_DIR, f"{uuid.uuid4()}_wave.png")

    # ì˜¤ë””ì˜¤ 30ì´ˆ ì¶”ì¶œ
    subprocess.run([
        "ffmpeg","-y",
        "-i", video_path,
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-t", "30",
        wav
    ])

    # numpy ë¡œ ë¡œë“œ
    data, _ = _load_wav_numpy(wav)
    n = len(data)

    # íŒŒí˜• ê·¸ë¦¬ê¸°
    img = np.zeros((height, width), dtype=np.uint8)

    for x in range(width):
        idx = int((x / width) * n)
        val = abs(data[idx]) / 32768.0
        h = int(val * (height/2))
        mid = height//2
        img[mid-h:mid+h, x] = 255

    cv2.imwrite(png, img)

    with open(png, "rb") as f:
        enc = base64.b64encode(f.read()).decode()

    try:
        os.remove(wav)
        os.remove(png)
    except:
        pass

    return enc

def generate_wave_png(wav_path: str, width=2000, height=300):
    import matplotlib.pyplot as plt
    import numpy as np
    import io
    import base64
    import wave
    import contextlib

    with contextlib.closing(wave.open(wav_path, "rb")) as w:
        frames = w.readframes(w.getnframes())
        sr = w.getframerate()

    sig = np.frombuffer(frames, dtype=np.int16).astype(np.float32)
    sig = sig / np.max(np.abs(sig))

    fig = plt.figure(figsize=(width/100, height/100), dpi=100)
    plt.plot(sig)
    plt.fill_between(range(len(sig)), sig, color="white", alpha=0.7)
    plt.axis("off")

    buf = io.BytesIO()
    plt.savefig(buf, format="png", transparent=True)
    plt.close(fig)
    buf.seek(0)

    b64 = base64.b64encode(buf.read()).decode("utf-8")
    return "data:image/png;base64," + b64


def load_yolo_data(video_path: str, offset: float = 0.0):
    """
    YOLO ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  sync offset ë§Œí¼ time ë³´ì • ì ìš©.
    """
    import json
    from pathlib import Path
    import config

    name = Path(video_path).name
    yolo_file = Path(config.WORK_DIR) / f"{name}_yolo.json"

    if not yolo_file.exists():
        return []

    data = json.loads(yolo_file.read_text(encoding="utf-8"))

    corrected = []
    for row in data:
        t = row["time"] + offset   # â† offset ë³´ì •

        if t < 0:
            continue  # ì˜ë¦° ì•ë¶€ë¶„ ì œê±°

        corrected.append({
            **row,
            "time": t
        })

    return corrected
